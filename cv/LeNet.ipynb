{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入需要的包\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import numpy as np\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, Linear\n",
    "\n",
    "# 定义 LeNet 网络结构\n",
    "class LeNet(fluid.dygraph.Layer):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        # 创建卷积和池化层块，每个卷积层使用Sigmoid激活函数，后面跟着一个2x2的池化\n",
    "        self.conv1 = Conv2D(num_channels=1, num_filters=6, filter_size=5, act='sigmoid')\n",
    "        self.pool1 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "        self.conv2 = Conv2D(num_channels=6, num_filters=16, filter_size=5, act='sigmoid')\n",
    "        self.pool2 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "        # 创建第3个卷积层\n",
    "        self.conv3 = Conv2D(num_channels=16, num_filters=120, filter_size=4, act='sigmoid')\n",
    "        # 创建全连接层，第一个全连接层的输出神经元个数为64， 第二个全连接层输出神经元个数为分类标签的类别数\n",
    "        self.fc1 = Linear(input_dim=120, output_dim=64, act='sigmoid')\n",
    "        self.fc2 = Linear(input_dim=64, output_dim=num_classes)\n",
    "    # 网络的前向计算过程\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = fluid.layers.reshape(x, [x.shape[0], -1])\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<paddle.fluid.dygraph.nn.Conv2D object at 0x7f59d6031258>, <paddle.fluid.dygraph.nn.Pool2D object at 0x7f59d6031360>, <paddle.fluid.dygraph.nn.Conv2D object at 0x7f59d60313b8>, <paddle.fluid.dygraph.nn.Pool2D object at 0x7f59d60314c0>, <paddle.fluid.dygraph.nn.Conv2D object at 0x7f59d6031518>, <paddle.fluid.dygraph.nn.Linear object at 0x7f59d6031620>, <paddle.fluid.dygraph.nn.Linear object at 0x7f59d6031728>]\n",
      "conv2d_0 [3, 6, 24, 24] [6, 1, 5, 5] [6]\n",
      "pool2d_0 [3, 6, 12, 12]\n",
      "conv2d_1 [3, 16, 8, 8] [16, 6, 5, 5] [16]\n",
      "pool2d_1 [3, 16, 4, 4]\n",
      "conv2d_2 [3, 120, 1, 1] [120, 16, 4, 4] [120]\n",
      "linear_0 [3, 64] [120, 64] [64]\n",
      "linear_1 [3, 10] [64, 10] [10]\n"
     ]
    }
   ],
   "source": [
    "# 输入数据形状是 [N, 1, H, W]\n",
    "# 这里用np.random创建一个随机数组作为输入数据\n",
    "x = np.random.randn(*[3,1,28,28])\n",
    "x = x.astype('float32')\n",
    "with fluid.dygraph.guard():\n",
    "    # 创建LeNet类的实例，指定模型名称和分类的类别数目\n",
    "    m = LeNet(num_classes=10)\n",
    "    # 通过调用LeNet从基类继承的sublayers()函数，\n",
    "    # 查看LeNet中所包含的子层\n",
    "    print(m.sublayers())\n",
    "    # 将numpy.ndarray转化成paddle中的tensor\n",
    "    x = fluid.dygraph.to_variable(x)\n",
    "    for item in m.sublayers():\n",
    "        # item是LeNet类中的一个子层\n",
    "        # 查看经过子层之后的输出数据形状\n",
    "        try:\n",
    "            x = item(x)\n",
    "        except:\n",
    "            x = fluid.layers.reshape(x, [x.shape[0], -1])\n",
    "            x = item(x)\n",
    "        if len(item.parameters())==2:\n",
    "            # 查看卷积和全连接层的数据和参数的形状，\n",
    "            # 其中item.parameters()[0]是权重参数w，item.parameters()[1]是偏置参数b\n",
    "            print(item.full_name(), x.shape, item.parameters()[0].shape, item.parameters()[1].shape)\n",
    "        else:\n",
    "            # 池化层没有参数\n",
    "            print(item.full_name(), x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "# GoogLeNet模型代码\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, BatchNorm, Linear\n",
    "from paddle.fluid.dygraph.base import to_variable\n",
    "\n",
    "# 定义Inception块\n",
    "class Inception(fluid.dygraph.Layer):\n",
    "    def __init__(self, c0,c1, c2, c3, c4, **kwargs):\n",
    "        '''\n",
    "        Inception模块的实现代码，\n",
    "        \n",
    "        c1,  图(b)中第一条支路1x1卷积的输出通道数，数据类型是整数\n",
    "        c2，图(b)中第二条支路卷积的输出通道数，数据类型是tuple或list, \n",
    "               其中c2[0]是1x1卷积的输出通道数，c2[1]是3x3\n",
    "        c3，图(b)中第三条支路卷积的输出通道数，数据类型是tuple或list, \n",
    "               其中c3[0]是1x1卷积的输出通道数，c3[1]是3x3\n",
    "        c4,  图(b)中第一条支路1x1卷积的输出通道数，数据类型是整数\n",
    "        '''\n",
    "        super(Inception, self).__init__()\n",
    "        # 依次创建Inception块每条支路上使用到的操作\n",
    "        self.p1_1 = Conv2D(num_channels=c0, num_filters=c1, \n",
    "                           filter_size=1, act='relu')\n",
    "        self.p2_1 = Conv2D(num_channels=c0, num_filters=c2[0], \n",
    "                           filter_size=1, act='relu')\n",
    "        self.p2_2 = Conv2D(num_channels=c2[0], num_filters=c2[1], \n",
    "                           filter_size=3, padding=1, act='relu')\n",
    "        self.p3_1 = Conv2D(num_channels=c0, num_filters=c3[0], \n",
    "                           filter_size=1, act='relu')\n",
    "        self.p3_2 = Conv2D(num_channels=c3[0], num_filters=c3[1], \n",
    "                           filter_size=5, padding=2, act='relu')\n",
    "        self.p4_1 = Pool2D(pool_size=3, \n",
    "                           pool_stride=1,  pool_padding=1, \n",
    "                           pool_type='max')\n",
    "        self.p4_2 = Conv2D(num_channels=c0, num_filters=c4, \n",
    "                           filter_size=1, act='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 支路1只包含一个1x1卷积\n",
    "        p1 = self.p1_1(x)\n",
    "        # 支路2包含 1x1卷积 + 3x3卷积\n",
    "        p2 = self.p2_2(self.p2_1(x))\n",
    "        # 支路3包含 1x1卷积 + 5x5卷积\n",
    "        p3 = self.p3_2(self.p3_1(x))\n",
    "        # 支路4包含 最大池化和1x1卷积\n",
    "        p4 = self.p4_2(self.p4_1(x))\n",
    "        # 将每个支路的输出特征图拼接在一起作为最终的输出结果\n",
    "        return fluid.layers.concat([p1, p2, p3, p4], axis=1)  \n",
    "    \n",
    "class GoogLeNet(fluid.dygraph.Layer):\n",
    "    def __init__(self):\n",
    "        super(GoogLeNet, self).__init__()\n",
    "        # GoogLeNet包含五个模块，每个模块后面紧跟一个池化层\n",
    "        # 第一个模块包含1个卷积层\n",
    "        self.conv1 = Conv2D(num_channels=3, num_filters=64, filter_size=7, \n",
    "                            padding=3, act='relu')\n",
    "        # 3x3最大池化\n",
    "        self.pool1 = Pool2D(pool_size=3, pool_stride=2,  \n",
    "                            pool_padding=1, pool_type='max')\n",
    "        # 第二个模块包含2个卷积层\n",
    "        self.conv2_1 = Conv2D(num_channels=64, num_filters=64, \n",
    "                              filter_size=1, act='relu')\n",
    "        self.conv2_2 = Conv2D(num_channels=64, num_filters=192, \n",
    "                              filter_size=3, padding=1, act='relu')\n",
    "        # 3x3最大池化\n",
    "        self.pool2 = Pool2D(pool_size=3, pool_stride=2,  \n",
    "                            pool_padding=1, pool_type='max')\n",
    "        # 第三个模块包含2个Inception块\n",
    "        self.block3_1 = Inception(192, 64, (96, 128), (16, 32), 32)\n",
    "        self.block3_2 = Inception(256, 128, (128, 192), (32, 96), 64)\n",
    "        # 3x3最大池化\n",
    "        self.pool3 = Pool2D(pool_size=3, pool_stride=2,  \n",
    "                               pool_padding=1, pool_type='max')\n",
    "        # 第四个模块包含5个Inception块\n",
    "        self.block4_1 = Inception(480, 192, (96, 208), (16, 48), 64)\n",
    "        self.block4_2 = Inception(512, 160, (112, 224), (24, 64), 64)\n",
    "        self.block4_3 = Inception(512, 128, (128, 256), (24, 64), 64)\n",
    "        self.block4_4 = Inception(512, 112, (144, 288), (32, 64), 64)\n",
    "        self.block4_5 = Inception(528, 256, (160, 320), (32, 128), 128)\n",
    "        # 3x3最大池化\n",
    "        self.pool4 = Pool2D(pool_size=3, pool_stride=2,  \n",
    "                               pool_padding=1, pool_type='max')\n",
    "        # 第五个模块包含2个Inception块\n",
    "        self.block5_1 = Inception(832, 256, (160, 320), (32, 128), 128)\n",
    "        self.block5_2 = Inception(832, 384, (192, 384), (48, 128), 128)\n",
    "        # 全局池化，尺寸用的是global_pooling，pool_stride不起作用\n",
    "        self.pool5 = Pool2D(pool_stride=1, \n",
    "                               global_pooling=True, pool_type='avg')\n",
    "        self.fc = Linear(input_dim=1024, output_dim=1, act=None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.conv1(x))\n",
    "        x = self.pool2(self.conv2_2(self.conv2_1(x)))\n",
    "        x = self.pool3(self.block3_2(self.block3_1(x)))\n",
    "        x = self.block4_3(self.block4_2(self.block4_1(x)))\n",
    "        x = self.pool4(self.block4_5(self.block4_4(x)))\n",
    "        x = self.pool5(self.block5_2(self.block5_1(x)))\n",
    "        x = fluid.layers.reshape(x, [x.shape[0], -1])\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e97849ec6298>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogLeNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "with fluid.dygraph.guard():\n",
    "    model = GoogLeNet()\n",
    "\n",
    "train(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
